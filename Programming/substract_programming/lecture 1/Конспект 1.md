# Основы программирования: введение в кодирование

Вы абсолютно правы. Приношу извинения — мой предыдущий «конспект» действительно был просто структурным планом, перечнем тем, а не связным изложением материала. Давайте я напишу его по-другому: как полноценный, связный текст, который передает ход мысли лектора и логику повествования, как будто вы записываете его в тетрадь.

***

### **Конспект вводной лекции курса «Основы программирования»**

**Лектор:** Александр Григорьин
**Тема:** Введение в кодирование информации и теоретическую информатику.

**1. Введение и цель занятия**
Лектор начинает с приветствия и объясняет, что это первое, теоретическое занятие курса. Его основная цель — не научить писать код, а **заложить понятийный аппарат**. Это как выучить новый язык: нужно понять и запомнить слова (термины), которые будут использоваться все оставшееся время. Кому-то это покажется простым, кому-то сложным, но без этого фундамента двигаться дальше будет трудно.

**2. Фундаментальная идея: компьютер — это калькулятор**
Первое, что нужно твердо усвоить: **компьютер оперирует только числами**. Все, что он обрабатывает, — будь то текст, картинка, музыка или сложная программа, — это в своей основе поток нулей и единиц. Любая абстракция, с которой работает программист (например, «объект», «структура данных», «пользователь»), в памяти компьютера представлена в виде чисел или наборов чисел. Главный совет на будущее: если вы запутались в сложной абстракции, спросите себя: **«А в виде какого числа (или набора чисел) это существует в памяти?»**. Этот вопрос помогает вернуться к основам и все прояснить.

**3. Что такое кодирование и зачем оно нужно**
Человек не может воспринимать бесконечный поток 0 и 1. Нам нужны правила, чтобы превращать этот поток во что-то понятное: в число, букву, цвет пикселя. Этот процесс преобразования и называется **кодированием**. Обратный процесс (из понятной формы в поток битов) — декодированием. Разные типы информации (числа, текст, изображение) кодируются по своим, особым правилам. В рамках курса мы лишь слегка коснемся этих правил, но важно понять сам принцип.

**4. Основа всего: позиционные системы счисления**
Чтобы кодировать числа, нужно вспомнить математику, а именно — **позиционные системы счисления**. Человек пользуется десятичной системой (основание 10, цифры 0-9). Любое число в ней можно разложить по разрядам. Например, число 5479 — это не просто последовательность цифр, а:
`5 * 1000 + 4 * 100 + 7 * 10 + 9 * 1`, или, что то же самое, `5*10³ + 4*10² + 7*10¹ + 9*10⁰`.

**Важен принцип:** вес цифры зависит от ее позиции (разряда) в числе. Цифра 5 в числе 5479 «весит» не 5, а 5000, потому что стоит в разряде тысяч.

**5. Двоичная система — родной язык компьютера**
Для компьютера десятичная система неудобна и неэффективна с инженерной точки зрения. Его «родная» система — **двоичная** (основание 2). В ней всего две цифры: 0 и 1 (бинарный ноль и бинарная единица).

**Логика работы с ней абсолютно такая же**, как и с десятичной! Все та же позиционность и те же правила сложения. Просто алфавит короче. Когда мы складываем 1 + 1 в двоичной системе, цифр для ответа «2» нет, поэтому происходит **перенос в старший разряд**, и получается `10₂` (читается «один-ноль» в двоичной системе), что равно 2 в десятичной.

**Важный момент:** чтобы избежать путаницы, систему счисления числа часто указывают маленькой цифрой внизу (индексом). `10₂` (двоичное) — это совсем не `10₁₀` (десятичное, «десять»).

**6. Бит и байт: кирпичики памяти**
Минимальная ячейка для хранения информации — это **бит**. Он может находиться только в одном из двух состояний: 0 или 1. Этого, очевидно, мало для практических задач.

Поэтому биты объединяют в группы. Стандартная и минимально адресуемая единица памяти — **байт**, состоящий из 8 бит. Почему именно 8? Это исторически сложившийся компромисс между удобством работы (группы, кратные степеням двойки, очень удобны для схемотехники) и сложностью реализации в «железе».

**7. Что можно поместить в один байт?**
Один байт — это 8 бит. Если записать в него все единицы (`11111111₂`), это будет максимальное число. Переведем его в десятичную систему, используя развернутую форму, но с основанием 2:
`1*2⁷ + 1*2⁶ + ... + 1*2⁰ = 128 + 64 + 32 + 16 + 8 + 4 + 2 + 1 = 255`.

Таким образом, **в один байт можно записать целое неотрицательное число от 0 до 255**. Всего это 256 различных значений (2⁸). Визуально байт часто записывают, разбивая на две тетрады (по 4 бита): `1111 1111` — так легче читать.

**8. Опасность: переполнение (overflow)**
Что произойдет, если мы попробуем прибавить 1 к максимальному числу в байте (255)?
`11111111₂ + 1 = ?`
Произойдет перенос, который пойдет за пределы отведенных 8 бит. Этот «девятый» бит в обычной ячейке байта не существует, он теряется. В результате в наших 8 битах окажутся все нули. `255 + 1 = 0`.

Это явление называется **переполнением**. Для наглядности можно представить байт как циферблат или кольцо значений от 0 до 255. Дойдя до 255 и сделав шаг вперед, вы снова окажетесь на 0. Это критически важное для программиста понятие, источник многих ошибок.

**9. Объединение байтов. Слова.**
Если одного байта мало (например, чтобы записать число 256 или зарплату программиста), байты объединяют в группы:
*   **Слово (Word)** = 2 байта = 16 бит. Может хранить числа от 0 до 65 535 (2¹⁶ значений).
*   **Двойное слово (Double Word, DWord)** = 4 байта = 32 бита. Диапазон до ~4.29 млрд.
*   **Четверное слово (Quad Word, QWord)** = 8 байт = 64 бита. Огромный диапазон.

Эти термины (Word, DWord) — из области теоретической информатики и архитектуры процессоров. В конкретных языках программирования типы данных будут называться иначе (например, `int`, `long`).

**10. Как компьютер работает с памятью**
Память (например, оперативная) — это линейная последовательность пронумерованных ячеек-байтов. Нумерация всегда начинается с 0.

Чтобы прочитать число, сохраненное в памяти, компьютеру нужно знать две вещи:
1.  **Адрес** — номер первого байта, с которого начинается это число.
2.  **Тип (размер)** данных — байт это, слово или четверное слово? Зная начало и размер, компьютер автоматически понимает, где конец данных (Начало + Размер - 1).

**Пример:** если число типа QWord (8 байт) хранится по адресу 5, компьютер обратится к байту 5, а затем прочитает еще 7 следующих байтов (с 6 по 12).

**Важно:** данные в памяти не обязаны идти плотно друг за другом. Между ними могут быть «пропуски» (неиспользованные ячейки или выравнивание для повышения скорости доступа).

**11. Заключение и итоги**
Первое занятие было посвящено основам языков, на которых говорит и думает компьютер:
1.  **Числа** — универсальный язык данных.
2.  **Двоичная система** — естественный способ представления чисел в железе.
3.  **Биты и байты** — фундаментальные единицы информации и памяти.
4.  **Кодирование** — перевод между человеческим и машинным представлением.
5.  **Переполнение** — ключевое явление, которое нужно контролировать.
6.  **Организация памяти** — линейная, адресуемая байтами.

Лектор подчеркивает, что эта теоретическая база — самый важный фундамент. Без четкого понимания, как данные (особенно числа) представлены в компьютере, дальнейшее погружение в программирование будет подобно строительству дома на песке. Все последующие темы курса будут опираться на эти понятия.